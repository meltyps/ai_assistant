try: 
    from local_database.intents import task_intents
    import stanza
    import sqlalchemy
    from sqlalchemy.orm import sessionmaker
    from sqlTable import engine, Task
except ImportError:
    from add_files.local_database.intents import task_intents
    import stanza
    import sqlalchemy
    from sqlalchemy.orm import sessionmaker
    from add_files.sqlTable import engine, Task
# from add_files.local_database.intents import task_intents

class CommandAnalyzer:
    _nlp = stanza.Pipeline(lang="ru", processors="tokenize,pos,lemma", tokenize_no_ssplit=True)  
    _Session = sessionmaker(bind=engine)

    def __init__(self, user_text: str):
        self.user_text = user_text
        self.user_lemmas = self._text_to_lemmas(user_text)

    @classmethod
    def _text_to_lemmas(cls, text: str) -> set:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ª–µ–º–º."""
        doc = cls._nlp(text)
        return {word.lemma for sentence in doc.sentences for word in sentence.words}

    def analyze(self):
        for intents, phrases in task_intents.items():
            if any(phrase in self.user_text.lower() for phrase in phrases):
                return intents

            
    def morph_analyze(self):
        """–ù–∞—Ö–æ–¥–∏—Ç –∑–∞–¥–∞—á–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ª–µ–º–º."""
        matches = []  # —Å–ø–∏—Å–æ–∫ (title, description, count)
        max_count = -1

        with self._Session() as session:
            tasks = session.query(Task.title, Task.description).all()

            for title, description in tasks:
                task_lemmas = self._text_to_lemmas(f"{title} {description}")
                count = len(self.user_lemmas & task_lemmas)

                if count > max_count:
                    max_count = count
                    matches = [(title, description, count)]  # —Å–±—Ä–∞—Å—ã–≤–∞–µ–º, –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –ª—É—á—à–µ
                elif count == max_count:
                    matches.append((title, description, count))  # –¥–æ–±–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ —Ä–∞–≤–Ω—ã

        if not matches:
            print("‚ùå –ü–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return None

        # –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –æ–¥–Ω–æ ‚Äî —Å—Ä–∞–∑—É –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
        if len(matches) == 1:
            return matches[0]

        # –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Å–∫–æ–ª—å–∫–æ ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö –∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        print("üîç –ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π:")
        for i, (title, desc, cnt) in enumerate(matches, start=1):
            print(f"\n{i}. üìå {title}\nüìù {desc}\n–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –ª–µ–º–º: {cnt}")

        while True:
            choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –∑–∞–¥–∞—á–∏, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å (–∏–ª–∏ 0, –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —É–¥–∞–ª—è—Ç—å): ").strip()
            if choice.isdigit():
                choice = int(choice)
                if 0 <= choice <= len(matches):
                    break
            print("‚ö† –í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä.")

        if choice == 0:
            return matches  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ, –Ω–∏—á–µ–≥–æ –Ω–µ —É–¥–∞–ª—è—è
        else:
            removed = matches.pop(choice)
            print(f"‚ùå –ó–∞–¥–∞—á–∞ '{removed[0]}' —É–¥–∞–ª–µ–Ω–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
            return matches

'''           
"word"	word	–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞
"normal_form"	parsed.normal_form	–õ–µ–º–º–∞ ‚Äî –Ω–∞—á–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ —Å–ª–æ–≤–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, —É —Å–ª–æ–≤–∞ "—à—ë–ª" –±—É–¥–µ—Ç "–∏–¥—Ç–∏"
"part_of_speech"	str(parsed.tag.POS)	–ß–∞—Å—Ç—å —Ä–µ—á–∏: NOUN (—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ), VERB (–≥–ª–∞–≥–æ–ª), ADJF (–ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ) –∏ —Ç.–¥.
"tag"	str(parsed.tag)	–ü–æ–ª–Ω—ã–π –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä: —á–∞—Å—Ç—å —Ä–µ—á–∏ + —Ä–æ–¥, —á–∏—Å–ª–æ, –ø–∞–¥–µ–∂ –∏ –¥—Ä.
'''
            
#print(CommandAnalyzer(input("Enter the text: ")).analyze())
#print(CommandAnalyzer(input("Enter the text: ")).morph_analyze())
